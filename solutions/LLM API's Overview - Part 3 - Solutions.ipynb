{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42574114-8d5c-4354-a7e9-ec8420a07624",
   "metadata": {},
   "source": [
    "## Structured Output: Guaranteed Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ebfe5-04bb-4ad1-8685-258b2f362ba0",
   "metadata": {},
   "source": [
    "Structured output refers to the ability of the `ChatCompletions` API to return responses in a predefined format, such as a JSON object or a Pydantic Model. This is particularly useful when you need the model to adhere to a specific schema for downstream processing or integration with other systems. By defining the expected structure, you can ensure the response is validated and parsed into a predictable format. \n",
    "\n",
    "Key Features of Structured Outputs\n",
    "\n",
    "1. Customizable Response Format\n",
    "    - You can specify the expected structure of the response using the response_format parameter.\n",
    "    - This can be defined as either a JSON schema or a Pydantic model, depending on your requirements.\n",
    "2. Using JSON Schema with create:\n",
    "    - The `chat.completions.create` method allows you to provide a JSON schema via the `response_format` parameter.\n",
    "    - This guides the model to generate responses in the desired structure without requiring Python-based schema definitions.\n",
    "3. Using Pydantic Models with parse\n",
    "    - The `chat.completions.parse` method supports validation and parsing using Pydantic models.\n",
    "    - This is ideal for scenarios where you need Python-based schema definitions and strict adherance to the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b0955c",
   "metadata": {},
   "source": [
    "### Why would we need this?\n",
    "\n",
    "In Part 2, we saw that we could ask the model to format its response as a JSON object using a prompt. This is a big step up from unstructured text, but it's still fundamentally a suggestion, not a guarantee.\n",
    "\n",
    "Let's see what happens when we try to extract information from a simple sentence and ask for a JSON response. Our goal is to get a clean JSON object that we can immediately load and use in our Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bec5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up our client first\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# Read the API_KEY\n",
    "with open('API_KEY.txt', 'r') as file:\n",
    "    API_KEY = file.read()\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=API_KEY, # Make sure to use your key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ca4fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "```json\n",
      "{\n",
      "  \"subject\": \"The researcher\",\n",
      "  \"verb\": \"analyzed\",\n",
      "  \"object\": \"the data\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Our prompt asks for a specific JSON structure\n",
    "prompt = \"\"\"\n",
    "Extract the grammatical components from the following sentence.\n",
    "Please respond with ONLY a JSON object with the keys 'subject', 'verb', and 'object'.\n",
    "\n",
    "Sentence: The researcher analyzed the data.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    ")\n",
    "\n",
    "raw_content = response.choices[0].message.content\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(raw_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf81b7",
   "metadata": {},
   "source": [
    "Now, let's try to parse this output as JSON, which is what you would do in any real-world data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4d86810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- FAILED to Parse JSON ---\n",
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    parsed_json = json.loads(raw_content)\n",
    "    print(\"--- Successfully Parsed JSON ---\")\n",
    "    print(parsed_json)\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"--- FAILED to Parse JSON ---\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86addae0",
   "metadata": {},
   "source": [
    "### Why Did That Fail?\n",
    "ðŸ”” Question: Look at the raw output from the LLM. Why did the json.loads() function crash?\n",
    "\n",
    "You'll likely see one of these common failure modes:\n",
    "\n",
    "1. Conversational Chit-Chat: The model might wrap the JSON in helpful text, like:\n",
    "\n",
    "    >\"Sure, here is the JSON you requested: { ... }\"\n",
    "    <br><br>\n",
    "    \"{ ... } I hope this helps!\"\n",
    "2. Markdown Code Blocks: \n",
    "    <br><br>\n",
    "    Often, the model will format the JSON within a markdown block, which looks like this:\n",
    "    ```json\n",
    "    {\n",
    "        \"subject\": \"The researcher\",\n",
    "        \"verb\": \"analyzed\",\n",
    "        \"object\": \"the data\"\n",
    "    }\n",
    "    ```\n",
    "3. Inconsistent Formatting\n",
    "    <br><br>Sometimes it might use single quotes instead of double quotes, which is invalid in JSON. Or forgot to properly close a bracket. Since the output is non deterministic there's no way to always guarantee proper formatting from just a text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66664656",
   "metadata": {},
   "source": [
    "While you could write a bunch of string manipulation code `.strip(), .replace(), etc.` to clean this up, that's brittle and unreliable. If you're processing 10,000 documents, you need a system that works every single time. Your research pipeline will break if even a small percentage of responses are not in the exact format you expect.\n",
    "\n",
    "This is the core problem that guaranteed structured output solves. We need to move from prompting for a format to demanding it.\n",
    "\n",
    "This is where the response_format parameter and Pydantic models come in. They provide a strict \"contract\" with the API, ensuring the response is not just close to what you want, but is a perfectly formatted, validated, and ready-to-use Python object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec8d71",
   "metadata": {},
   "source": [
    "### A Step in the Right Direction: `response_format`\n",
    "Okay, that last attempt was messy. Constantly cleaning up the model's output is not a scalable solution.\n",
    "\n",
    "Fortunately, the `ChatCompletions` API has a built-in parameter to help with this: `response_format`. By setting response_format={\"type\": \"json_object\"}, we can instruct the model to enable \"JSON mode.\"\n",
    "\n",
    "When JSON mode is enabled, the model is constrained to only generate strings that can be parsed into valid JSON. This eliminates the problems of conversational wrappers and markdown formatting.\n",
    "\n",
    "Let's try our previous example again, but this time using JSON mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5a9c991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output ---\n",
      "{\n",
      "  \"subject\": \"The researcher\",\n",
      "  \"verb\": \"analyzed\",\n",
      "  \"object\": \"the data\"\n",
      "}\n",
      "\\n--- Successfully Parsed JSON ---\n",
      "{'subject': 'The researcher', 'verb': 'analyzed', 'object': 'the data'}\n",
      "Subject: The researcher\n"
     ]
    }
   ],
   "source": [
    "# Our prompt is now simpler. We don't need to beg for JSON in the text itself.\n",
    "prompt = \"Extract the subject, verb, and object from this sentence: The researcher analyzed the data.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-nano-9b-v2:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"} # This is the key parameter!\n",
    ")\n",
    "\n",
    "raw_content = response.choices[0].message.content\n",
    "print(\"--- Raw LLM Output ---\")\n",
    "print(raw_content)\n",
    "\n",
    "# Now, let's try to parse it again.\n",
    "try:\n",
    "    parsed_json = json.loads(raw_content)\n",
    "    print(\"\\\\n--- Successfully Parsed JSON ---\")\n",
    "    print(parsed_json)\n",
    "    print(f\"Subject: {parsed_json.get('subject')}\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"\\\\n--- FAILED to Parse JSON ---\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e165840",
   "metadata": {},
   "source": [
    "### The New Problem: Correct Syntax, Wrong Schema\n",
    "This is much better! We got a clean, parsable JSON object directly from the API.\n",
    "\n",
    "But we're not out of the woods yet. JSON mode guarantees syntactic validity (the output is valid JSON), but it does not guarantee semantic validity (the output matches the schema or structure we actually need).\n",
    "\n",
    "The model is still free to:\n",
    "- Invent new keys (\"theme\": \"research\").\n",
    "- Forget required keys (\"object\").\n",
    "- Return the wrong data type (e.g., a number instead of a string).\n",
    "\n",
    "Let's design a prompt that might confuse the model and see if we can expose this weakness. We'll ask it for a user's name and age, expecting specific keys and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d2cf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw LLM Output from Confusing Prompt ---\n",
      "{\n",
      "  \"user_name\": \"Alex\",\n",
      "  \"user_age\": 25\n",
      "}\n",
      "\\n--- Validation Passed ---\n",
      "Alex is 25 years old.\n"
     ]
    }
   ],
   "source": [
    "# We expect a JSON object like: {\"user_name\": str, \"user_age\": int}\n",
    "\n",
    "confusing_prompt = \"Extract the user's details. The user, Alex, is 25 years old.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-nano-9b-v2:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant designed to output JSON.\"},\n",
    "        {\"role\": \"user\", \"content\": confusing_prompt}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "raw_content = response.choices[0].message.content\n",
    "print(\"--- Raw LLM Output from Confusing Prompt ---\")\n",
    "print(raw_content)\n",
    "\n",
    "# Let's check if our expected keys exist and have the correct types\n",
    "try:\n",
    "    data = json.loads(raw_content)\n",
    "    user_name = data['user_name']\n",
    "    user_age = data['user_age']\n",
    "\n",
    "    if not isinstance(user_age, int):\n",
    "        print(\"\\\\n--- VALIDATION FAILED: 'user_age' should be an integer! ---\")\n",
    "    else:\n",
    "        print(\"\\\\n--- Validation Passed ---\")\n",
    "        print(f\"{user_name} is {user_age} years old.\")\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"\\\\n--- VALIDATION FAILED: Missing key in response: {e} ---\")\n",
    "except json.JSONDecodeError as e:\n",
    "     print(f\"\\\\n--- FAILED to Parse JSON ---\")\n",
    "     print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6ca86",
   "metadata": {},
   "source": [
    "ðŸ”” Question: Run the cell above a few times. Do you always get the keys user_name and user_age? Does the model sometimes use different keys like \"name\" or \"age\"? Does it ever return the age as a string (\"25\") instead of an integer (25)?\n",
    "\n",
    "This inconsistency is the final hurdle. For a truly robust data pipeline, we need to guarantee not just the format (JSON) but also the schema (the exact keys and data types). Again even if you don't see the responses fail in this small sample, when running a script 10,000 times. You don't want there ever to be mistakes or it could cause your whole workflow to fail. \n",
    "\n",
    "This is what Pydantic models are for, and it's what we'll cover next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba34422-2c98-449a-b53e-f85136cc195c",
   "metadata": {},
   "source": [
    "### This leads us back to: Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145970c",
   "metadata": {},
   "source": [
    "We've seen that prompting for JSON is unreliable and that `response_format={\"type\": \"json_object\"}` only guarantees valid syntax, not the correct content or structure. We need a way to define a strict schemaâ€”a blueprint for our dataâ€”and force the model's output to conform to it.\n",
    "\n",
    "This is precisely what the `Pydantic` library was built for.\n",
    "\n",
    "`Pydantic` allows you to define a data structure as a Python class. When we combine this with the special `.parse()` method from the client, we are no longer just hoping for the right output; we are guaranteeing it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10897244",
   "metadata": {},
   "source": [
    "#### Your First Pydantic Model\n",
    "Let's solve our simple sentence-parsing problem, this time with a guarantee of success.\n",
    "\n",
    "First, you'll need to install Pydantic:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918d33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b6030",
   "metadata": {},
   "source": [
    "Now, let's define our \"contract\" as a Python class. It looks simple, but it's incredibly powerful. Each attribute defines an expected key and its required data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ae52e9c-8ea7-4356-a7c3-9c2e0e2a55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# First, define the structure of your desired output as a Pydantic class.\n",
    "# This class IS the schema.\n",
    "class ParsedSentence(BaseModel):\n",
    "    subject: str\n",
    "    verb: str\n",
    "    obj: str # 'obj' is the key, and it MUST be a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900f7fc",
   "metadata": {},
   "source": [
    "Instead of using client.chat.completions.create, we will use client.chat.completions.parse. This special method is designed to work with Pydantic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a1171-2c16-40be-bf7a-1fc3497c7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt is dead simple. All the complexity is in our Pydantic model.\n",
    "prompt = \"The researcher analyzed the data.\"\n",
    "\n",
    "# We use .parse() and pass our Pydantic class to the response_format parameter.\n",
    "response = client.chat.completions.parse(\n",
    "    model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    response_format=ParsedSentence, # This is the magic!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "424bfc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "704f30ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Raw Response Object ---\n",
      "{'choices': [{'finish_reason': 'stop',\n",
      "              'index': 0,\n",
      "              'logprobs': None,\n",
      "              'message': {'annotations': None,\n",
      "                          'audio': None,\n",
      "                          'content': '{ \"subject\": \"researcher\", \"verb\": '\n",
      "                                     '\"analyzed\", \"obj\": \"data\" }',\n",
      "                          'function_call': None,\n",
      "                          'parsed': {'obj': 'data',\n",
      "                                     'subject': 'researcher',\n",
      "                                     'verb': 'analyzed'},\n",
      "                          'reasoning': None,\n",
      "                          'refusal': None,\n",
      "                          'role': 'assistant',\n",
      "                          'tool_calls': None},\n",
      "              'native_finish_reason': 'stop'}],\n",
      " 'created': 1759979401,\n",
      " 'id': 'gen-1759979401-ws7G92DRzanNZr5TuBHN',\n",
      " 'model': 'mistralai/mistral-small-3.2-24b-instruct:free',\n",
      " 'object': 'chat.completion',\n",
      " 'provider': 'Chutes',\n",
      " 'service_tier': None,\n",
      " 'system_fingerprint': None,\n",
      " 'usage': {'completion_tokens': 26,\n",
      "           'completion_tokens_details': None,\n",
      "           'prompt_tokens': 564,\n",
      "           'prompt_tokens_details': None,\n",
      "           'total_tokens': 590}}\n"
     ]
    }
   ],
   "source": [
    "# The response object is slightly different from before.\n",
    "print(\"--- Raw Response Object ---\")\n",
    "pprint(response.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6297712f",
   "metadata": {},
   "source": [
    "Look at the output. The message object now contains a special field: parsed. This is our Pydantic object, fully validated and ready to use.\n",
    "\n",
    "ðŸ”” Question: What do you notice that is special about this parsed field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4b6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.ParsedSentence"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pay attention to the type of the parsed field.\n",
    "type(response.choices[0].message.parsed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4709e5ec-a6c6-4b5e-b403-c4fa9d944318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Accessing the Parsed Data ---\n",
      "Subject: researcher\n",
      "Verb: analyzed\n",
      "Object: data\n"
     ]
    }
   ],
   "source": [
    "# No more json.loads() or try/except blocks needed!\n",
    "# We can directly access our validated data.\n",
    "parsed_data = response.choices[0].message.parsed\n",
    "\n",
    "print(\"\\\\n--- Accessing the Parsed Data ---\")\n",
    "print(f\"Subject: {parsed_data.subject}\")\n",
    "print(f\"Verb: {parsed_data.verb}\")\n",
    "print(f\"Object: {parsed_data.obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16854f87",
   "metadata": {},
   "source": [
    "This is the gold standard for reliable data extraction. By defining a Pydantic BaseModel, you create a robust and unbreakable contract with the LLM, ensuring that every response you get is structured exactly the way you need it to be for your downstream analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca292856",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23bee65",
   "metadata": {},
   "source": [
    "Now it's your turn to build some Pydantic models. We'll work through a series of short challenges, each designed to teach you a core feature. The goal is to get your hands dirty and build confidence before we tackle a larger, more complex problem.\n",
    "\n",
    "For each challenge, you will:\n",
    "\n",
    "Define the Pydantic BaseModel that matches the required schema.\n",
    "\n",
    "Make the API call using client.chat.completions.parse and your new model.\n",
    "\n",
    "Print the result to verify that your model worked correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232fcbe5",
   "metadata": {},
   "source": [
    "### Challenge 1: Basic Data Types\n",
    "**Goal**: Extract the name (string), age (integer), and student status (boolean) from the text below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc2f73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# The text to parse\n",
    "prompt_text = \"Meet David Chen. He is 42 years old and works as an engineer, so he is not a student.\"\n",
    "\n",
    "# 1. DEFINE YOUR SCHEMA HERE\n",
    "# Create a Pydantic class called 'PersonProfile' with the following fields:\n",
    "# - name: str\n",
    "# - age: int\n",
    "# - is_student: bool\n",
    "class PersonProfile(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    is_student: bool\n",
    "\n",
    "\n",
    "# 2. MAKE THE API CALL\n",
    "# Use client.chat.completions.parse with your PersonProfile model.\n",
    "\n",
    "response = client.chat.completions.parse(\n",
    "    model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ],\n",
    "    response_format=PersonProfile, # Use your Pydantic model here\n",
    ")\n",
    "\n",
    "# 3. PRINT THE RESULT\n",
    "parsed_result = response.choices[0].message.parsed\n",
    "print(parsed_result)\n",
    "print(f\"The type of 'age' is: {type(parsed_result.age)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ec4976",
   "metadata": {},
   "source": [
    "Key Concept: Pydantic handles the conversion from the model's text output (e.g., \"42\") to the correct Python data type (the integer 42)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78192e",
   "metadata": {},
   "source": [
    "### Challenge 2: Handling Lists of Strings\n",
    "\n",
    "**Goal**: Extract the name of the committee and a list of all its members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1084472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# The text to parse\n",
    "prompt_text = \"The budget committee is composed of several members: Maria, David, and Susan.\"\n",
    "\n",
    "# 1. DEFINE YOUR SCHEMA HERE\n",
    "# Create a Pydantic class called 'Committee' with the following fields:\n",
    "# - committee_name: str\n",
    "# - members: List[str]\n",
    "\n",
    "class Committee(BaseModel):\n",
    "    committee_name: str\n",
    "    members: List[str]\n",
    "\n",
    "# 2. MAKE THE API CALL\n",
    "response = client.chat.completions.parse(\n",
    "    model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ],\n",
    "    response_format=Committee,  # Use your Pydantic model here\n",
    ")\n",
    "\n",
    "# 3. PRINT THE RESULT\n",
    "parsed_result = response.choices[0].message.parsed\n",
    "print(f\"Committee: {parsed_result.committee_name}\")\n",
    "print(f\"Members: {parsed_result.members}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c12d3a",
   "metadata": {},
   "source": [
    "Key Concept: Use List[<type>] (e.g., List[str]) to extract a list of items."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d61fcdf",
   "metadata": {},
   "source": [
    "### Challenge 3: Optional Fields\n",
    "**Goal**: Extract a product's name and its rating. The rating might not always be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc69a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Optional\n",
    "\n",
    "# Text 1: Contains a rating\n",
    "prompt_text_1 = \"The new ACME Anvil 2.0 is a fantastic product. I'd give it a 5 out of 5 stars.\"\n",
    "\n",
    "# Text 2: Does NOT contain a rating\n",
    "prompt_text_2 = \"We have just received a shipment of the ACME Anvil 2.0.\"\n",
    "\n",
    "# 1. DEFINE YOUR SCHEMA HERE\n",
    "# Create a Pydantic class called 'Product' with the following fields:\n",
    "# - product_name: str\n",
    "# - rating: Optional[int]  # This field can be an integer or None\n",
    "\n",
    "class Product(BaseModel):\n",
    "    product_name: str\n",
    "    rating: Optional[int]  # This field can be an integer or None\n",
    "\n",
    "# 2. MAKE THE API CALL (Try it with both prompt_text_1 and prompt_text_2!)\n",
    "response_1 = client.chat.completions.parse(\n",
    "    model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_text_1}\n",
    "    ],\n",
    "    response_format=Product,\n",
    ")\n",
    "\n",
    "response_2 = client.chat.completions.parse(\n",
    "    model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_text_2}\n",
    "    ], \n",
    "    response_format=Product,\n",
    ")\n",
    "   \n",
    "# 3. PRINT THE RESULT\n",
    "parsed_result_1 = response_1.choices[0].message.parsed\n",
    "print(parsed_result_1.model_dump())\n",
    "\n",
    "parsed_result_2 = response_2.choices[0].message.parsed\n",
    "print(parsed_result_2.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9b62a4",
   "metadata": {},
   "source": [
    "Key Concept: Use Optional[<type>] for data that might be missing in the source text. This prevents your code from crashing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522abed7",
   "metadata": {},
   "source": [
    "### Challenge 4: Nesting Models\n",
    "Goal: Extract information about a report, including a nested object for the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# The text to parse\n",
    "prompt_text = \"The 2023 annual report on climate change was written by Dr. Eleanor Vance.\"\n",
    "\n",
    "# 1. DEFINE YOUR SCHEMAS HERE\n",
    "# First, create an 'Author' model with fields:\n",
    "# - first_name: str\n",
    "# - last_name: str\n",
    "\n",
    "# class Author(BaseModel):\n",
    "class Author(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "\n",
    "# Next, create a 'Report' model with fields:\n",
    "# - title: str\n",
    "# - year: int\n",
    "# - author: Author  # Use the Author model as the type here!\n",
    "\n",
    "class Report(BaseModel):\n",
    "    title: str\n",
    "    year: int\n",
    "    author: Author\n",
    "\n",
    "\n",
    "# 2. MAKE THE API CALL\n",
    "response = client.chat.completions.parse(\n",
    "    model=\"mistralai/mistral-small-3.2-24b-instruct:free\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt_text}\n",
    "    ],\n",
    "    response_format=Report,\n",
    ")\n",
    "\n",
    "# 3. PRINT THE RESULT\n",
    "parsed_result = response.choices[0].message.parsed\n",
    "print(f\"Report: '{parsed_result.title}' ({parsed_result.year})\")\n",
    "print(f\"Author: {parsed_result.author.first_name} {parsed_result.author.last_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb1ed35",
   "metadata": {},
   "source": [
    "Key Concept: You can create complex schemas by nesting models within each other, which is essential for representing real-world data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bdd757",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f728a4",
   "metadata": {},
   "source": [
    "## Part 3 Wrap-Up: From Suggestion to Guarantee\n",
    "Congratulations! You have just mastered the single most important technique for building reliable, scalable applications with Large Language Models.\n",
    "\n",
    "Let's quickly recap the journey you took in this section:\n",
    "\n",
    "1. **The Problem with Prompts**: You started by seeing why simply asking for JSON in a prompt is unreliable. The model can add conversational text or markdown, breaking any automated data processing pipeline.\n",
    "2. **The Limits of JSON Mode**: You learned that response_format={\"type\": \"json_object\"} is a step up, guaranteeing valid JSON syntax, but it offers no protection against the model inventing keys or using the wrong data typesâ€”it doesn't guarantee the schema.\n",
    "3. **The Power of Pydantic**: Finally, you learned how to use Pydantic models with the .parse() method to create an unbreakable contract with the LLM. Through the challenges, you proved you can now reliably extract:\n",
    "    - Correct data types (strings, integers, booleans)\n",
    "    - Lists of items\n",
    "    - Optional and nested data\n",
    "\n",
    "You've moved from suggesting a format to guaranteeing it. This skill is the cornerstone of any serious research or production workflow that uses LLMs for data extraction, classification, or analysis.\n",
    "\n",
    "Now that you can reliably get structured data out of a model, what's next? In Part 4, we'll explore how to give the model abilities to interact with the outside world using Tool Calling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "D_Lab-M2S9YoIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
