{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99ebdde",
   "metadata": {},
   "source": [
    "# Part 4: Tool Calling - Giving Your LLM Research Superpowers\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h3>üéØ Workshop Goals (Part 4)</h3>\n",
    "<p>In this final hour, we will give our LLM the ability to interact with the outside world. This is the key to unlocking its potential as a true research assistant. You will learn:</p>\n",
    "<ul>\n",
    "<li><strong>Why a Researcher Needs Tools:</strong> Understand the inherent limitations of LLMs, such as knowledge cutoffs and the inability to access your private data or the live internet.</li>\n",
    "<li><strong>The Tool Calling Loop:</strong> Master the fundamental request-execute-respond pattern that powers all modern AI agents.</li>\n",
    "<li><strong>Building a Research Assistant:</strong> Create a set of tools that could help automate a social science research workflow.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b9eee4",
   "metadata": {},
   "source": [
    "1. The Researcher's Dilemma: The Brain in the Jar\n",
    "So far, we've treated the LLM as an incredibly knowledgeable, fast, and reliable data processor. You give it text, and it gives you back perfectly structured data. This is a powerful skill for tasks like the COVID-19 narrative analysis we've discussed.\n",
    "\n",
    "But for a researcher, this is only half the battle. Your work isn't static; it's a dynamic process. This exposes two major limitations of a standard LLM:\n",
    "\n",
    "1. **The Knowledge Cutoff**: The model's knowledge stops the moment its training was completed. It cannot read the latest paper published on arXiv yesterday, access the most recent census data, or know about a news event that happened this morning. Its knowledge is a fixed library, not a live internet connection.\n",
    "2. **The Inability to Take Action**: The LLM is isolated. It can't access your local files, query your university's research database, or even run a simple statistical calculation. It can write a script to analyze your data, but it can't run it.\n",
    "\n",
    "Imagine you have a brilliant research assistant who is locked in the university's library archives from two years ago. They can read and synthesize any book in that room with superhuman speed, but they can't use a web browser, make a phone call, or open an Excel spreadsheet on your computer.\n",
    "\n",
    "Tool calling is the act of giving that brilliant assistant a laptop and an internet connection. It connects the \"brain\" of the LLM to the \"hands\" of real-world tools, allowing it to overcome these limitations and become a true partner in your research workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8726ec5d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### How it Works: The Tool Calling Loop\n",
    "At its core, tool calling is a multi-step conversation between your code and the LLM. It's not a single request and response, but a sequence of exchanges. We call this the Tool Calling Loop.\n",
    "\n",
    "Let's make this concrete with a simple, non-research example: asking for the current time. The LLM doesn't have a live clock, so it will need a tool for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e3e2a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Step 1: Define Your Tool in Python\n",
    "First, we write a standard Python function that does the thing we need. This function is our \"tool.\" It's just regular code that runs on your machine, not in the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134bd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need our client and some other libraries\n",
    "import json\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "# Read the API_KEY\n",
    "with open('API_KEY.txt', 'r') as file:\n",
    "    API_KEY = file.read() \n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bf396aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  TOOL EXECUTED: get_current_time() ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2026-02-04 22:41:32'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define our tool. A simple Python function to get the current time.\n",
    "def get_current_time():\n",
    "    \"\"\"Gets the current local time.\"\"\"\n",
    "    # In a real application, this could be doing anything:\n",
    "    # querying a database, calling another API, reading a file, etc.\n",
    "    print(\"---  TOOL EXECUTED: get_current_time() ---\")\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "get_current_time()  # Test the tool works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0d6a0",
   "metadata": {},
   "source": [
    "#### Step 2: Describe the Tool to the LLM\n",
    "\n",
    "Next, we need to create a \"manual\" or \"menu\" of our available tools for the LLM. We define this using a **specific JSON structure**. The description is the most important part! It's how the LLM decides when to use your tool. It should be clear and descriptive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bca9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the \"menu\" of tools we will offer the LLM.\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_current_time\",\n",
    "            \"description\": \"Use this function to get the current date and time.\",\n",
    "            \"parameters\": { # This tool takes no parameters\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cb41c3",
   "metadata": {},
   "source": [
    "#### Step 3: The First API Call - The LLM Asks for a Tool\n",
    "\n",
    "Now, we make our first API call. This is where the magic happens. The structure of the call is very similar to what you've seen before, but with two new, crucial parameters: `tools` and `tool_choice`.\n",
    "\n",
    "- `tools`: This is where we pass the \"menu\" of available tools that we defined in the previous step. It's a list of JSON objects describing each function the model is allowed to request.\n",
    "- `tool_choice`: This parameter controls how the model uses the tools.\n",
    "    - \"auto\" (the default): The model decides for itself whether to use a tool or not based on the user's prompt. This is what you'll use most of the time.\n",
    "    - \"none\": This forces the model to not use any tools and just respond with a standard message.\n",
    "    - {\"type\": \"function\", \"function\": {\"name\": \"my_function\"}}: This forces the model to use a specific function.\n",
    "\n",
    "This `tools` parameter is a core feature of the OpenAI API, and its standardization has been adopted by many other providers, including OpenRouter, making it a key skill to learn. You can read the complete, official documentation on this feature for more details.\n",
    "\n",
    "Official Documentation: [OpenAI API Reference - Tool Calling](https://platform.openai.com/docs/guides/function-calling)\n",
    "\n",
    "Let's make the call. Notice the response we get back. The LLM doesn't answer the question directly. Instead, it asks us to run a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52eb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The user's question that requires a tool\n",
    "messages = [{\"role\": \"user\", \"content\": \"What time is it?\"}]\n",
    "\n",
    "# Make the first API call, providing the tools menu\n",
    "response = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-nano-9b-v2:free\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79b6af2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': None,\n",
      " 'audio': None,\n",
      " 'content': '',\n",
      " 'function_call': None,\n",
      " 'reasoning': 'Okay, the user is asking for the current time. Let me check '\n",
      "              \"what tools I have available. Oh, there's a function called \"\n",
      "              'get_current_time that retrieves the date and time. Since the '\n",
      "              'user wants to know the time, I should call that function. The '\n",
      "              \"function doesn't require any parameters, so I just need to \"\n",
      "              'trigger it. Once I get the response from the tool, I can format '\n",
      "              'the time in a user-friendly way and provide the answer. Let me '\n",
      "              \"make sure I'm using the correct syntax for the tool call. Yep, \"\n",
      "              \"I'll generate the JSON object inside the tool_call tags as \"\n",
      "              'specified.\\n',\n",
      " 'reasoning_details': [{'format': 'unknown',\n",
      "                        'index': 0,\n",
      "                        'text': 'Okay, the user is asking for the current '\n",
      "                                'time. Let me check what tools I have '\n",
      "                                \"available. Oh, there's a function called \"\n",
      "                                'get_current_time that retrieves the date and '\n",
      "                                'time. Since the user wants to know the time, '\n",
      "                                'I should call that function. The function '\n",
      "                                \"doesn't require any parameters, so I just \"\n",
      "                                'need to trigger it. Once I get the response '\n",
      "                                'from the tool, I can format the time in a '\n",
      "                                'user-friendly way and provide the answer. Let '\n",
      "                                \"me make sure I'm using the correct syntax for \"\n",
      "                                \"the tool call. Yep, I'll generate the JSON \"\n",
      "                                'object inside the tool_call tags as '\n",
      "                                'specified.\\n',\n",
      "                        'type': 'reasoning.text'}],\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [{'function': {'arguments': '{}', 'name': 'get_current_time'},\n",
      "                 'id': 'EuFxOr3JQ',\n",
      "                 'index': 0,\n",
      "                 'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "# Inspect the response\n",
    "response_message = response.choices[0].message\n",
    "pprint(response_message.model_dump())  # Pretty-print the full response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccba6e28",
   "metadata": {},
   "source": [
    "üîî Question: Look at the response_message output. What is the content of the message? What is the value of the tool_calls field?\n",
    "\n",
    "You'll see that the message content is null. The LLM hasn't said anything. Instead, it has returned a `tool_calls` object. This is an instruction from the LLM to your code, saying: \"I need to answer the user, but first, please run the `get_current_time` function for me.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75c34da",
   "metadata": {},
   "source": [
    "#### Step 4: Your Code Executes the Tool and Sends Back the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346886c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  TOOL EXECUTED: get_current_time() ---\n",
      "--- Current Message History ---\n",
      "{'content': 'What time is it?', 'role': 'user'}\n",
      "\n",
      "ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='EuFxOr3JQ', function=Function(arguments='{}', name='get_current_time'), type='function', index=0)], reasoning=\"Okay, the user is asking for the current time. Let me check what tools I have available. Oh, there's a function called get_current_time that retrieves the date and time. Since the user wants to know the time, I should call that function. The function doesn't require any parameters, so I just need to trigger it. Once I get the response from the tool, I can format the time in a user-friendly way and provide the answer. Let me make sure I'm using the correct syntax for the tool call. Yep, I'll generate the JSON object inside the tool_call tags as specified.\\n\", reasoning_details=[{'format': 'unknown', 'index': 0, 'type': 'reasoning.text', 'text': \"Okay, the user is asking for the current time. Let me check what tools I have available. Oh, there's a function called get_current_time that retrieves the date and time. Since the user wants to know the time, I should call that function. The function doesn't require any parameters, so I just need to trigger it. Once I get the response from the tool, I can format the time in a user-friendly way and provide the answer. Let me make sure I'm using the correct syntax for the tool call. Yep, I'll generate the JSON object inside the tool_call tags as specified.\\n\"}])\n",
      "\n",
      "{'content': '2026-02-04 22:44:40',\n",
      " 'name': 'get_current_time',\n",
      " 'role': 'tool',\n",
      " 'tool_call_id': 'EuFxOr3JQ'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, append the LLM's instruction to call a tool to our message history\n",
    "messages = [{\"role\": \"user\", \"content\": \"What time is it?\"}] # Our original user question\n",
    "messages.append(response_message)\n",
    "\n",
    "# Get the ID of the tool call\n",
    "tool_call_id = response_message.tool_calls[0].id\n",
    "\n",
    "# Call our actual Python function\n",
    "tool_output = get_current_time()\n",
    "\n",
    "# Now, append the *output* of our function to the message history\n",
    "# This tells the model what the result of its requested tool call was.\n",
    "messages.append(\n",
    "    {\n",
    "        \"tool_call_id\": tool_call_id,\n",
    "        \"role\": \"tool\",\n",
    "        \"name\": \"get_current_time\",\n",
    "        \"content\": tool_output, # The actual result from our Python function\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"--- Current Message History ---\")\n",
    "for msg in messages:\n",
    "    pprint(msg)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be92b11",
   "metadata": {},
   "source": [
    "#### Step 5: The Second API Call - The LLM Gives the Final Answer\n",
    "Now that the LLM has the real-time information it needed, we make one final API call. This time, the model uses the context from the tool's output to generate a natural, human-readable answer to the user's original question.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ecd752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the second API call with the complete message history\n",
    "second_response = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-nano-9b-v2:free\",\n",
    "    messages=messages,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35afebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Final Answer from LLM ---\n",
      "The current time is **2026-02-04 at 22:44:40**. Let me know if you'd like this converted to a specific time zone!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the final answer\n",
    "final_answer = second_response.choices[0].message.content\n",
    "print(\"\\\\n--- Final Answer from LLM ---\")\n",
    "print(final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87496c77",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Warning:** Notice we've switched models here from `mistral-instruct` in the previous parts of the workshop to `tongyi-deepresearch-30b`. This is becuase some models don't support tool calling. On OpenRouter's website you can filter by models that support tool calling. Always ensure the model you're using can, otherwise this will not work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1087f",
   "metadata": {},
   "source": [
    "#### ü•ä [Challenge] Your First Research Tool: The Paper Fetcher (10 mins)\n",
    "Now it's your turn to build the entire tool-calling loop from scratch.\n",
    "\n",
    "**Your Goal**: Create a tool that allows the LLM to look up information about a (fake) academic paper based on its ID. This simulates a common research task: querying a database like arXiv, PubMed, or JSTOR.\n",
    "\n",
    "**Your Task**: You will need to write the code for all 5 steps of the loop to answer the user's question: \"Can you tell me the title and author of the paper 2305.15334?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55507a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOOL EXECUTED: Searching Real API for 2305.15334 ---\n",
      "{\"paperId\": \"7d8905a1fd288068f12c8347caeabefd36d0dd6c\", \"title\": \"Gorilla: Large Language Model Connected with Massive APIs\", \"year\": 2023, \"authors\": [{\"authorId\": \"80887461\", \"name\": \"Shishir G. Patil\"}, {\"authorId\": \"1993655237\", \"name\": \"Tianjun Zhang\"}, {\"authorId\": \"2153692009\", \"name\": \"Xin Wang\"}, {\"authorId\": \"49988044\", \"name\": \"Joseph E. Gonzalez\"}]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def get_paper_details(paper_id: str):\n",
    "    \"\"\"\n",
    "    Gets the title and author for a given paper ID from Semantic Scholar.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL EXECUTED: Searching Real API for {paper_id} ---\")\n",
    "    \n",
    "    # We use the public Semantic Scholar API\n",
    "    # It returns clean JSON by default!\n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/arXiv:{paper_id}?fields=title,authors,year\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            return response.text # It's already a JSON string!\n",
    "        else:\n",
    "            return json.dumps({\"error\": \"Paper not found\", \"status\": response.status_code})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "# Test it!\n",
    "print(get_paper_details(\"2305.15334\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05537905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# --- Step 1: Define Your Tool in Python (Backup in case API fails) ---\n",
    "# This function simulates fetching data from an academic database.\n",
    "# It should take one argument: 'paper_id' (a string).\n",
    "def get_paper_details_backup(paper_id: str):\n",
    "    \"\"\"\n",
    "    Gets the title and author for a given paper ID from a mock database.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL EXECUTED: Searching for paper {paper_id} ---\")\n",
    "    \n",
    "    # A mock database of academic papers\n",
    "    mock_database = {\n",
    "        \"2305.15334\": {\n",
    "            \"title\": \"The Role of Social Media in Political Polarization\",\n",
    "            \"author\": \"Dr. Eleanor Vance\",\n",
    "            \"year\": 2023,\n",
    "        },\n",
    "        \"1706.03762\": {\n",
    "            \"title\": \"Attention Is All You Need\",\n",
    "            \"author\": \"Ashish Vaswani et al.\",\n",
    "            \"year\": 2017,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    paper_info = mock_database.get(paper_id, \"Paper not found.\")\n",
    "    return json.dumps(paper_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950c8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 2: Describe the Tool to the LLM ---\n",
    "# Create the 'tools' list with the definition for 'get_paper_details'.\n",
    "# Make sure you correctly define the 'parameters' the function expects!\n",
    "# It should have one required parameter: 'paper_id' of type 'string'.\n",
    "\n",
    "tool = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_paper_details\",\n",
    "            \"description\": \"Fetch details about a specific academic paper.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"paper_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The ID of the paper to retrieve.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"paper_id\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d0c391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3, 4, and 5: Execute the Full Loop ---\n",
    "# Write the code to handle the entire conversation.\n",
    "\n",
    "# paper_id = \"2305.15334\"\n",
    "# Choose your own paper!\n",
    "paper_id = \"\"\n",
    "\n",
    "# 1. Define the initial message list with the user's prompt.\n",
    "user_prompt = f\"Can you tell me the title and author of the paper {paper_id}?\"\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "# 2. Make the first API call to get the tool_calls object.\n",
    "response = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-nano-9b-v2:free\",\n",
    "    messages=messages,\n",
    "    tools=tool\n",
    ")\n",
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de7b16eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': None,\n",
      " 'audio': None,\n",
      " 'content': '',\n",
      " 'function_call': None,\n",
      " 'reasoning': 'Okay, the user is asking for the title and author of paper ID '\n",
      "              \"2305.15334. Let me check the tools I have. There's a function \"\n",
      "              'called get_paper_details that takes a paper_id. The required '\n",
      "              'parameter is paper_id, which the user provided. So I should '\n",
      "              \"call that function with the given ID. I don't have any other \"\n",
      "              \"tools, so this should be the right approach. I'll generate the \"\n",
      "              'tool call with the paper_id 2305.15334.\\n',\n",
      " 'reasoning_details': [{'format': 'unknown',\n",
      "                        'index': 0,\n",
      "                        'text': 'Okay, the user is asking for the title and '\n",
      "                                'author of paper ID 2305.15334. Let me check '\n",
      "                                \"the tools I have. There's a function called \"\n",
      "                                'get_paper_details that takes a paper_id. The '\n",
      "                                'required parameter is paper_id, which the '\n",
      "                                'user provided. So I should call that function '\n",
      "                                \"with the given ID. I don't have any other \"\n",
      "                                'tools, so this should be the right approach. '\n",
      "                                \"I'll generate the tool call with the paper_id \"\n",
      "                                '2305.15334.\\n',\n",
      "                        'type': 'reasoning.text'}],\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [{'function': {'arguments': '{\"paper_id\": \"2305.15334\"}',\n",
      "                              'name': 'get_paper_details'},\n",
      "                 'id': 'RfuCQYg5Z',\n",
      "                 'index': 0,\n",
      "                 'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(response_message.model_dump())  # Inspect the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e0c9dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Can you tell me the title and author of the paper 2305.15334?',\n",
      "  'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0721e0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32376935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Can you tell me the title and author of the paper 2305.15334?',\n",
      "  'role': 'user'},\n",
      " ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='RfuCQYg5Z', function=Function(arguments='{\"paper_id\": \"2305.15334\"}', name='get_paper_details'), type='function', index=0)], reasoning=\"Okay, the user is asking for the title and author of paper ID 2305.15334. Let me check the tools I have. There's a function called get_paper_details that takes a paper_id. The required parameter is paper_id, which the user provided. So I should call that function with the given ID. I don't have any other tools, so this should be the right approach. I'll generate the tool call with the paper_id 2305.15334.\\n\", reasoning_details=[{'format': 'unknown', 'index': 0, 'type': 'reasoning.text', 'text': \"Okay, the user is asking for the title and author of paper ID 2305.15334. Let me check the tools I have. There's a function called get_paper_details that takes a paper_id. The required parameter is paper_id, which the user provided. So I should call that function with the given ID. I don't have any other tools, so this should be the right approach. I'll generate the tool call with the paper_id 2305.15334.\\n\"}])]\n"
     ]
    }
   ],
   "source": [
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2761e416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOOL EXECUTED: Searching Real API for 2305.15334 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"paperId\": \"7d8905a1fd288068f12c8347caeabefd36d0dd6c\", \"title\": \"Gorilla: Large Language Model Connected with Massive APIs\", \"year\": 2023, \"authors\": [{\"authorId\": \"80887461\", \"name\": \"Shishir G. Patil\"}, {\"authorId\": \"1993655237\", \"name\": \"Tianjun Zhang\"}, {\"authorId\": \"2153692009\", \"name\": \"Xin Wang\"}, {\"authorId\": \"49988044\", \"name\": \"Joseph E. Gonzalez\"}]}\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_paper_details(\"2305.15334\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d21e651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paper_id': '2305.15334'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response_message.tool_calls[0].function.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8024b3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RfuCQYg5Z'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message.tool_calls[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54054478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOOL EXECUTED: Searching Real API for 2305.15334 ---\n"
     ]
    }
   ],
   "source": [
    "# 3. Check for tool_calls, execute the function, and append the results to the messages list.\n",
    "# (This part will be more complex than the time example, as you need to get the arguments!)\n",
    "# Maybe try printing response_message.tool_calls[0].arguments to see what the structure looks like. HINT: it is a dictionary with a key \"paper_id\".\n",
    "\n",
    "if response_message.tool_calls:\n",
    "    # ... your code to extract args, call the function, and append results ...\n",
    "    \n",
    "    # Extract the arguments for the tool call\n",
    "    tool_args = json.loads(response_message.tool_calls[0].function.arguments)\n",
    "    paper_id = tool_args.get(\"paper_id\")\n",
    "\n",
    "    # Call the get_paper_details function with the extracted arguments\n",
    "    tool_response = get_paper_details(paper_id)\n",
    "\n",
    "    # Append the tool response to the messages list\n",
    "    messages.append({\n",
    "        \"role\": \"user\", \n",
    "        \"content\": tool_response,\n",
    "        \"tool_call_id\": response_message.tool_calls[0].id,\n",
    "        \"role\": \"tool\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b3dae38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Can you tell me the title and author of the paper 2305.15334?',\n",
      "  'role': 'user'},\n",
      " ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='RfuCQYg5Z', function=Function(arguments='{\"paper_id\": \"2305.15334\"}', name='get_paper_details'), type='function', index=0)], reasoning=\"Okay, the user is asking for the title and author of paper ID 2305.15334. Let me check the tools I have. There's a function called get_paper_details that takes a paper_id. The required parameter is paper_id, which the user provided. So I should call that function with the given ID. I don't have any other tools, so this should be the right approach. I'll generate the tool call with the paper_id 2305.15334.\\n\", reasoning_details=[{'format': 'unknown', 'index': 0, 'type': 'reasoning.text', 'text': \"Okay, the user is asking for the title and author of paper ID 2305.15334. Let me check the tools I have. There's a function called get_paper_details that takes a paper_id. The required parameter is paper_id, which the user provided. So I should call that function with the given ID. I don't have any other tools, so this should be the right approach. I'll generate the tool call with the paper_id 2305.15334.\\n\"}]),\n",
      " {'content': '{\"paperId\": \"7d8905a1fd288068f12c8347caeabefd36d0dd6c\", \"title\": '\n",
      "             '\"Gorilla: Large Language Model Connected with Massive APIs\", '\n",
      "             '\"year\": 2023, \"authors\": [{\"authorId\": \"80887461\", \"name\": '\n",
      "             '\"Shishir G. Patil\"}, {\"authorId\": \"1993655237\", \"name\": \"Tianjun '\n",
      "             'Zhang\"}, {\"authorId\": \"2153692009\", \"name\": \"Xin Wang\"}, '\n",
      "             '{\"authorId\": \"49988044\", \"name\": \"Joseph E. Gonzalez\"}]}\\n',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'RfuCQYg5Z'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64fee47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Make the second API call to get the final, natural language answer.\n",
    "second_response = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-nano-9b-v2:free\",\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b16b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper with ID `2305.15334` has the following details:\n",
      "\n",
      "- **Title**: *Gorilla: Large Language Model Connected with Massive APIs*  \n",
      "- **Authors**:  \n",
      "  1. Shishir G. Patil  \n",
      "  2. Tianjun Zhang  \n",
      "  3. Xin Wang  \n",
      "  4. Joseph E. Gonzalez  \n",
      "\n",
      "This paper was published in 2023. Let me know if you need further details!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(second_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14e1cd",
   "metadata": {},
   "source": [
    "#### What's Next? Handling Multiple Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49630eb9",
   "metadata": {},
   "source": [
    "So far, our agent has used one tool to answer one question. But a real research workflow is more complex. You might need to ask a question that requires multiple pieces of information from different sources.\n",
    "\n",
    "For example: \"Can you find the title of paper 2305.15334 and also find its citations on Google Scholar?\"\n",
    "\n",
    "The LLM is smart enough to recognize this. Instead of making you go back and forth for each piece of information, it can request all the tools it needs in a single turn. This is called parallel tool calling.\n",
    "\n",
    "When this happens, the response_message.tool_calls object will no longer be a single item, but a list of tool calls. Your code needs to be ready to loop through this list, execute each requested tool, and gather all the results before sending them back to the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aece053",
   "metadata": {},
   "source": [
    "#### Example: A Multi-Tool Research Assistant\n",
    "Let's add a second tool to our paper fetcher and see how to handle a parallel request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "daeafc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use our get_paper_details function from before.\n",
    "\n",
    "def get_citations_for_paper(paper_id: str):\n",
    "    \"\"\"Gets the citation count for a paper from Semantic Scholar.\"\"\"\n",
    "    print(f\"--- TOOL EXECUTED: Checking Citations for {paper_id} ---\")\n",
    "    \n",
    "    url = f\"https://api.semanticscholar.org/graph/v1/paper/arXiv:{paper_id}?fields=citationCount\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return json.dumps({\n",
    "                \"paper_id\": paper_id, \n",
    "                \"citation_count\": data.get(\"citationCount\", 0)\n",
    "            })\n",
    "        else:\n",
    "            return json.dumps({\"error\": \"Paper not found\", \"status\": response.status_code})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "\n",
    "# Here is our new tool. It simulates another research task.\n",
    "def get_citations_for_paper_backup(paper_id: str):\n",
    "    \"\"\"Gets the number of citations for a paper from a mock database.\"\"\"\n",
    "    print(f\"--- TOOL EXECUTED: Getting citations for {paper_id} ---\")\n",
    "    mock_citation_database = {\n",
    "        \"2305.15334\": 121,\n",
    "        \"1706.03762\": 85000,\n",
    "    }\n",
    "    citations = mock_citation_database.get(paper_id, 0)\n",
    "    return json.dumps({\"paper_id\": paper_id, \"citation_count\": citations})\n",
    "\n",
    "# Now, our 'tools' menu has two functions available.\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\", \"function\": {\n",
    "            \"name\": \"get_paper_details\",\n",
    "            \"description\": \"Looks up the title and author of an academic paper given its unique ID.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {\"paper_id\": {\"type\": \"string\"}}, \"required\": [\"paper_id\"]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\", \"function\": {\n",
    "            \"name\": \"get_citations_for_paper\",\n",
    "            \"description\": \"Finds the number of citations for a given paper ID.\",\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {\"paper_id\": {\"type\": \"string\"}}, \"required\": [\"paper_id\"]}\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "737592c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOOL EXECUTED: Checking Citations for 2305.15334 ---\n",
      "{\"paper_id\": \"2305.15334\", \"citation_count\": 910}\n"
     ]
    }
   ],
   "source": [
    "# Test it!\n",
    "print(get_citations_for_paper(\"2305.15334\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26159c2",
   "metadata": {},
   "source": [
    "Now, watch how we adapt the loop to handle multiple tool calls. The key change is that we now **loop through** response_message.tool_calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30835d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A more complex prompt that requires BOTH tools.\n",
    "user_prompt = \"Please get me the title of paper 2305.15334 and also find out how many citations it has.\"\n",
    "messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "\n",
    "# 1. First API call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"nvidia/nemotron-nano-9b-v2:free\", \n",
    "    messages=messages, \n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")\n",
    "response_message = response.choices[0].message\n",
    "messages.append(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ebe7ad7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'annotations': None,\n",
      " 'audio': None,\n",
      " 'content': '',\n",
      " 'function_call': None,\n",
      " 'reasoning': 'Okay, let me tackle this user query. The user is asking for two '\n",
      "              'things: the title of paper with ID 2305.15334 and the number of '\n",
      "              'citations it has.\\n'\n",
      "              '\\n'\n",
      "              \"First, I need to check which tools are available. There's \"\n",
      "              'get_paper_details which takes a paper_id and returns title and '\n",
      "              \"author. Then there's get_citations_for_paper which also takes a \"\n",
      "              'paper_id and gives the citation count. \\n'\n",
      "              '\\n'\n",
      "              'So for the first part, I should call get_paper_details with the '\n",
      "              'provided paper ID. That should give the title. Then, for the '\n",
      "              'citations, I need to call get_citations_for_paper with the same '\n",
      "              'ID. \\n'\n",
      "              '\\n'\n",
      "              \"Wait, the user didn't mention the author, just the title and \"\n",
      "              'citations. But the get_paper_details function might return both '\n",
      "              'title and author. But since the user only asked for the title, '\n",
      "              \"I'll focus on that. \\n\"\n",
      "              '\\n'\n",
      "              'I need to make sure to call both functions. Since each tool '\n",
      "              'call is separate, I should make two tool calls here. The paper '\n",
      "              'ID is given as 2305.15334, which is a string, so the parameters '\n",
      "              'should be correct. \\n'\n",
      "              '\\n'\n",
      "              'No missing information here because the user provided the paper '\n",
      "              \"ID. So I don't need to ask for anything else. Just proceed to \"\n",
      "              'call both tools.\\n',\n",
      " 'reasoning_details': [{'format': 'unknown',\n",
      "                        'index': 0,\n",
      "                        'text': 'Okay, let me tackle this user query. The user '\n",
      "                                'is asking for two things: the title of paper '\n",
      "                                'with ID 2305.15334 and the number of '\n",
      "                                'citations it has.\\n'\n",
      "                                '\\n'\n",
      "                                'First, I need to check which tools are '\n",
      "                                \"available. There's get_paper_details which \"\n",
      "                                'takes a paper_id and returns title and '\n",
      "                                \"author. Then there's get_citations_for_paper \"\n",
      "                                'which also takes a paper_id and gives the '\n",
      "                                'citation count. \\n'\n",
      "                                '\\n'\n",
      "                                'So for the first part, I should call '\n",
      "                                'get_paper_details with the provided paper ID. '\n",
      "                                'That should give the title. Then, for the '\n",
      "                                'citations, I need to call '\n",
      "                                'get_citations_for_paper with the same ID. \\n'\n",
      "                                '\\n'\n",
      "                                \"Wait, the user didn't mention the author, \"\n",
      "                                'just the title and citations. But the '\n",
      "                                'get_paper_details function might return both '\n",
      "                                'title and author. But since the user only '\n",
      "                                \"asked for the title, I'll focus on that. \\n\"\n",
      "                                '\\n'\n",
      "                                'I need to make sure to call both functions. '\n",
      "                                'Since each tool call is separate, I should '\n",
      "                                'make two tool calls here. The paper ID is '\n",
      "                                'given as 2305.15334, which is a string, so '\n",
      "                                'the parameters should be correct. \\n'\n",
      "                                '\\n'\n",
      "                                'No missing information here because the user '\n",
      "                                \"provided the paper ID. So I don't need to ask \"\n",
      "                                'for anything else. Just proceed to call both '\n",
      "                                'tools.\\n',\n",
      "                        'type': 'reasoning.text'}],\n",
      " 'refusal': None,\n",
      " 'role': 'assistant',\n",
      " 'tool_calls': [{'function': {'arguments': '{\"paper_id\": \"2305.15334\"}',\n",
      "                              'name': 'get_paper_details'},\n",
      "                 'id': 'Fvz1pNcL8',\n",
      "                 'index': 0,\n",
      "                 'type': 'function'},\n",
      "                {'function': {'arguments': '{\"paper_id\": \"2305.15334\"}',\n",
      "                              'name': 'get_citations_for_paper'},\n",
      "                 'id': 'A2BEwD2TS',\n",
      "                 'index': 1,\n",
      "                 'type': 'function'}]}\n"
     ]
    }
   ],
   "source": [
    "# Sanity check: print the response to see the tool calls\n",
    "pprint(response_message.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23159a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'function': {'arguments': '{\"paper_id\": \"2305.15334\"}',\n",
      "              'name': 'get_paper_details'},\n",
      " 'id': 'Fvz1pNcL8',\n",
      " 'index': 0,\n",
      " 'type': 'function'}\n",
      "{'function': {'arguments': '{\"paper_id\": \"2305.15334\"}',\n",
      "              'name': 'get_citations_for_paper'},\n",
      " 'id': 'A2BEwD2TS',\n",
      " 'index': 1,\n",
      " 'type': 'function'}\n"
     ]
    }
   ],
   "source": [
    "for tool_call in response_message.tool_calls:\n",
    "    pprint(tool_call.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a652ca69",
   "metadata": {},
   "source": [
    "We can confirm that it has called both tools as expected!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6173171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LLM requested 2 tools ---\n",
      "--- TOOL EXECUTED: Searching Real API for 2305.15334 ---\n",
      "--- TOOL EXECUTED: Checking Citations for 2305.15334 ---\n"
     ]
    }
   ],
   "source": [
    "# 2. Execute ALL requested tools\n",
    "if response_message.tool_calls:\n",
    "    print(f\"--- LLM requested {len(response_message.tool_calls)} tools ---\")\n",
    "    \n",
    "    # This is the key change: We loop through each tool call requested by the model\n",
    "    for tool_call in response_message.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if function_name == \"get_paper_details\":\n",
    "            tool_output = get_paper_details(paper_id=function_args.get(\"paper_id\"))\n",
    "        elif function_name == \"get_citations_for_paper\":\n",
    "            tool_output = get_citations_for_paper(paper_id=function_args.get(\"paper_id\"))\n",
    "        \n",
    "        # We append one message to the history FOR EACH tool call.\n",
    "        messages.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": tool_output,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90f7893e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complete Message History ---\n",
      "[{'content': 'Please get me the title of paper 2305.15334 and also find out '\n",
      "             'how many citations it has.',\n",
      "  'role': 'user'},\n",
      " ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageFunctionToolCall(id='Fvz1pNcL8', function=Function(arguments='{\"paper_id\": \"2305.15334\"}', name='get_paper_details'), type='function', index=0), ChatCompletionMessageFunctionToolCall(id='A2BEwD2TS', function=Function(arguments='{\"paper_id\": \"2305.15334\"}', name='get_citations_for_paper'), type='function', index=1)], reasoning=\"Okay, let me tackle this user query. The user is asking for two things: the title of paper with ID 2305.15334 and the number of citations it has.\\n\\nFirst, I need to check which tools are available. There's get_paper_details which takes a paper_id and returns title and author. Then there's get_citations_for_paper which also takes a paper_id and gives the citation count. \\n\\nSo for the first part, I should call get_paper_details with the provided paper ID. That should give the title. Then, for the citations, I need to call get_citations_for_paper with the same ID. \\n\\nWait, the user didn't mention the author, just the title and citations. But the get_paper_details function might return both title and author. But since the user only asked for the title, I'll focus on that. \\n\\nI need to make sure to call both functions. Since each tool call is separate, I should make two tool calls here. The paper ID is given as 2305.15334, which is a string, so the parameters should be correct. \\n\\nNo missing information here because the user provided the paper ID. So I don't need to ask for anything else. Just proceed to call both tools.\\n\", reasoning_details=[{'format': 'unknown', 'index': 0, 'type': 'reasoning.text', 'text': \"Okay, let me tackle this user query. The user is asking for two things: the title of paper with ID 2305.15334 and the number of citations it has.\\n\\nFirst, I need to check which tools are available. There's get_paper_details which takes a paper_id and returns title and author. Then there's get_citations_for_paper which also takes a paper_id and gives the citation count. \\n\\nSo for the first part, I should call get_paper_details with the provided paper ID. That should give the title. Then, for the citations, I need to call get_citations_for_paper with the same ID. \\n\\nWait, the user didn't mention the author, just the title and citations. But the get_paper_details function might return both title and author. But since the user only asked for the title, I'll focus on that. \\n\\nI need to make sure to call both functions. Since each tool call is separate, I should make two tool calls here. The paper ID is given as 2305.15334, which is a string, so the parameters should be correct. \\n\\nNo missing information here because the user provided the paper ID. So I don't need to ask for anything else. Just proceed to call both tools.\\n\"}]),\n",
      " {'content': '{\"error\": \"Paper not found\", \"status\": 429}',\n",
      "  'name': 'get_paper_details',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'Fvz1pNcL8'},\n",
      " {'content': '{\"paper_id\": \"2305.15334\", \"citation_count\": 910}',\n",
      "  'name': 'get_citations_for_paper',\n",
      "  'role': 'tool',\n",
      "  'tool_call_id': 'A2BEwD2TS'}]\n"
     ]
    }
   ],
   "source": [
    "# Let's verify our message history so far after adding the messages from both tool calls in the cell above\n",
    "print(\"--- Complete Message History ---\")\n",
    "pprint(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "feeb25be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Second API call for the final answer\n",
    "second_response = client.chat.completions.create(model=\"nvidia/nemotron-nano-9b-v2:free\", messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c259e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\n--- Final LLM Answer ---\\nThe paper ID **2305.15334** was not found in the system (error 429: too many requests or unavailable data). However, the citation count for this paper is **910**. \n",
      "\n",
      "For the title, you may need to check platforms like arXiv.org directly using the paper ID, as the tool is returning an error. Let me know if you'd like further assistance!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\\\n--- Final LLM Answer ---\\\\n{second_response.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e27fc",
   "metadata": {},
   "source": [
    "### ü•ä Grand Finale Challenge: The Narrative Standardization Agent (20 mins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85d230",
   "metadata": {},
   "source": [
    "This is our final task. It will bring together everything you have learned to build a practical research assistant for the exact problem we started with: thematic coding of COVID-19 narratives.\n",
    "\n",
    "##### The Research Context\n",
    "Let's revisit our goal. We are social scientists with thousands of raw, unstructured narratives.\n",
    "\n",
    "A typical raw narrative (Our Input):\n",
    "> \"I was working at the hospital in the South Bronx, and we were running out of everything. It felt hopeless. Every day was a mix of profound sadness for the patients we lost and this incredible solidarity with my fellow nurses. We were all in it together.\"\n",
    "\n",
    "For this data to be useful, we need to process it into a clean, standardized format. This requires a clear \"codebook\" for our analysis and a defined structure for the output.\n",
    "\n",
    "For this challenge we want to identify:\n",
    "- The emotions expressed in each story\n",
    "- Mentions of material conditions (e.g. PPE shortages)\n",
    "- Instances of collective solidarity or isolation\n",
    "- Themes of grief, duty, or burnout\n",
    "- (New) Extract the location in the story and convert it to a location ISO Code For Categorization (South Bronx -> Bronx -> NYC-BX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11284b5e",
   "metadata": {},
   "source": [
    "##### Your Task Part 1: Build the Pydantic \"Codebook\"\n",
    "\n",
    "Before we can build the agent, we must define the structure of our final output. This is your first task. You will create the Pydantic models that will serve as the blueprint for our data.\n",
    "\n",
    "    A) Create the Emotion Codebook\n",
    "\n",
    "In qualitative research, a codebook ensures consistency. An `Enum` is the perfect way to enforce a strict codebook.\n",
    "\n",
    "Your task: Finish the `Enum` class called EmotionCode that allows for only the following string values: \"Sadness\", \"Solidarity\", \"Hopelessness\", \"Fear\", and \"Grief\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa63ea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "import json\n",
    "\n",
    "# --- Your Code Below ---\n",
    "# 1. Define the EmotionCode Enum here. We can use this to limit the values of the Emotion\n",
    "class EmotionCode(str, Enum):\n",
    "    SADNESS = \"Sadness\"\n",
    "    SOLIDARITY = \"Solidarity\"\n",
    "    # Continue with the rest here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38c4bd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sadness\n"
     ]
    }
   ],
   "source": [
    "print(EmotionCode.SADNESS.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a557a3",
   "metadata": {},
   "source": [
    "    B) Create the Final Schema\n",
    "\n",
    "Now, using your EmotionCode enum and the skills you learned in Part 3, define the final data structure.\n",
    "\n",
    "Your task: Create a Pydantic BaseModel called CodedNarrative. It should have the following fields:\n",
    "- summary: A required str.\n",
    "- emotions: A required List of EmotionCode enums.\n",
    "- material_conditions: A required List of str.\n",
    "- primary_borough: A required str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12e16691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Your Code Below ---\n",
    "# 2. Define the CodedNarrative BaseModel here.\n",
    "# It should use the EmotionCode Enum you created above.\n",
    "# class CodedNarrative(BaseModel):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc1e82",
   "metadata": {},
   "source": [
    "##### Your Task Part 2: Build the Agent\n",
    "Now that you have your output schema, you can build the agent that will produce it. I've provided the custom tool for you. Your job is to create the tool's schema and write the full loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51c0ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- I've provided this tool for you ---\n",
    "def get_borough_iso_code(borough_name: str):\n",
    "    \"\"\"\n",
    "    Takes a standardized NYC borough name and returns its official ISO-like code.\n",
    "    \"\"\"\n",
    "    print(f\"--- TOOL: Getting ISO code for: '{borough_name}' ---\")\n",
    "    # This mock database maps a standardized borough name to a code.\n",
    "    borough_code_database = {\n",
    "        \"Bronx\": \"NYC-BX\",\n",
    "        \"Queens\": \"NYC-QN\",\n",
    "        \"Manhattan\": \"NYC-MN\",\n",
    "        \"Brooklyn\": \"NYC-BK\",\n",
    "        \"Staten Island\": \"NYC-SI\"\n",
    "    }\n",
    "    code = borough_code_database.get(borough_name, \"Invalid Borough\")\n",
    "    return json.dumps({\"iso_code\": code})\n",
    "\n",
    "\n",
    "# 3. DEFINE THE TOOL SCHEMA\n",
    "# Create the 'tools' list with the JSON definition for the get_borough_iso_code function.\n",
    "# Its single parameter should be 'borough_name'.\n",
    "# tools = [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. BUILD THE AGENT\n",
    "# The raw narrative to be processed\n",
    "raw_narrative = (\n",
    "    \"I was working at the hospital in the South Bronx, and we were running out of everything. It felt hopeless. \"\n",
    "    \"Every day was a mix of profound sadness for the patients we lost and this incredible solidarity with my fellow nurses.\"\n",
    ")\n",
    "\n",
    "# The System Prompt is the \"brain\" of our agent. Note the two-step instruction for location.\n",
    "system_prompt = (\n",
    "    \"You are a social science research assistant. Your task is to thematically code a raw narrative about experiences in NYC during COVID-19. \"\n",
    "    \"First, carefully read the narrative to identify the NYC borough. You must standardize fuzzy locations (e.g., 'South Bronx') into a proper borough name (e.g., 'Bronx'). \"\n",
    "    \"Then, use the `get_borough_iso_code` tool with that standardized borough name. \"\n",
    "    \"Next, analyze the text to determine a one-sentence summary, the emotions expressed (which must conform to the provided EmotionCode enum), \"\n",
    "    \"and any material conditions mentioned. \"\n",
    "    \"Finally, combine all this information into a single JSON object that perfectly matches the `CodedNarrative` schema.\"\n",
    ")\n",
    "\n",
    "# Execute the FULL tool-calling loop.\n",
    "# It should end with a final call using .parse() and your CodedNarrative model to guarantee the output structure.\n",
    "\n",
    "# --- Your Code Below ---\n",
    "# 1. Start the conversation history\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": raw_narrative}\n",
    "]\n",
    "\n",
    "# 2. First API Call: The model will reason and ask to use the tool\n",
    "print(\"--- 1. Making first API call to request tool ---\")\n",
    "# response = client.chat.completions.create(\n",
    "#     ...\n",
    "# )\n",
    "\n",
    "response_message = response.choices[0].message\n",
    "messages.append(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbacd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response_message.model_dump())  # Inspect the response for tools requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb85a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Execute the tool the model requested\n",
    "if response_message.tool_calls:\n",
    "    tool_call = response_message.tool_calls[0]\n",
    "    function_name = tool_call.function.name\n",
    "    \n",
    "    # The model correctly infers that \"South Bronx\" should be \"Bronx\"\n",
    "    function_args = json.loads(tool_call.function.arguments)\n",
    "    borough_arg = function_args.get(\"borough_name\")\n",
    "    \n",
    "    # Call our Python function with the argument from the model\n",
    "    function_response = get_borough_iso_code(borough_name=borough_arg)\n",
    "    \n",
    "    # Append the tool's output to the conversation. Hint: you need (tool_call_id, role, name, content)\n",
    "    # messages.append({``\n",
    "    #     ...\n",
    "    # })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e36eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity Check the message structure\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d40cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final API Call: Use .parse() to get the final, validated Pydantic object\n",
    "print(\"--- 2. Making final .parse() call for structured output ---\")\n",
    "# final_response = client.chat.completions.parse(\n",
    "#     model=\"\",\n",
    "#     messages=messages,\n",
    "#     response_format= <Fill this out>,\n",
    "# )\n",
    "\n",
    "coded_narrative_object = final_response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ad0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Display the Final, Structured Result ---\n",
    "print(\"--- Final Coded Narrative (Pydantic Object) ---\")\n",
    "pprint(coded_narrative_object.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28710d0f",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "When you run the code, you will see the tool execution messages followed by the final structured JSON object.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"summary\": \"A healthcare worker in the Bronx describes feelings of hopelessness and sadness due to shortages but also experiences incredible solidarity with colleagues.\",\n",
    "  \"emotions\": [\n",
    "    \"Hopelessness\",\n",
    "    \"Sadness\",\n",
    "    \"Solidarity\"\n",
    "  ],\n",
    "  \"material_conditions\": [\n",
    "    \"running out of everything\"\n",
    "  ],\n",
    "  \"borough_iso_code\": \"NYC-BX\"\n",
    "}```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6a1b7e",
   "metadata": {},
   "source": [
    "---\n",
    "### Final Takeaways: From Chatbot to Research Partner\n",
    "Congratulations on completing this workshop! You've gone from making simple API calls to building a sophisticated, multi-step AI agent capable of performing a real research task.\n",
    "\n",
    "Let's recap the journey:\n",
    "\n",
    "1. **Prompting**: You started by learning that the \"prompt is the program.\" You learned to guide the LLM's behavior with system prompts and improve its reliability with few-shot examples.\n",
    "2. **Structured Output**: You then took control of the model's output. You moved from simply asking for JSON to guaranteeing it with Pydantic models and Enums, turning the LLM into a reliable data processor.\n",
    "3. **Tool Calling**: Finally, you gave the LLM superpowers. By connecting the model's \"brain\" to the \"hands\" of Python functions, you enabled it to interact with custom knowledge bases and standardize messy, real-world data.\n",
    "\n",
    "The most important takeaway is this: an LLM is not just a chatbot. It is a powerful reasoning engine that you can programmatically control and integrate into your research workflow. By combining clear instructions, structured schemas, and custom tools, you can transform it from a simple novelty into a reliable and scalable research partner.\n",
    "\n",
    "The skills you've learned today are the foundation for building any modern AI-powered application. We encourage you to take the code from this workshop, adapt it to your own research questions, and start building!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b7960",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
