{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42574114-8d5c-4354-a7e9-ec8420a07624",
   "metadata": {},
   "source": [
    "## Structured Output: Guaranteed Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ebfe5-04bb-4ad1-8685-258b2f362ba0",
   "metadata": {},
   "source": [
    "Structured output refers to the ability of the `ChatCompletions` API to return responses in a predefined format, such as a JSON object or a Pydantic Model. This is particularly useful when you need the model to adhere to a specific schema for downstream processing or integration with other systems. By defining the expected structure, you can ensure the response is validated and parsed into a predictable format. \n",
    "\n",
    "Key Features of Structured Outputs\n",
    "\n",
    "1. Customizable Response Format\n",
    "    - You can specify the expected structure of the response using the response_format parameter.\n",
    "    - This can be defined as either a JSON schema or a Pydantic model, depending on your requirements.\n",
    "2. Using JSON Schema with create:\n",
    "    - The `chat.completions.create` method allows you to provide a JSON schema via the `response_format` parameter.\n",
    "    - This guides the model to generate responses in the desired structure without requiring Python-based schema definitions.\n",
    "3. Using Pydantic Models with parse\n",
    "    - The `chat.completions.parse` method supports validation and parsing using Pydantic models.\n",
    "    - This is ideal for scenarios where you need Python-based schema definitions and strict adherance to the structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba34422-2c98-449a-b53e-f85136cc195c",
   "metadata": {},
   "source": [
    "### Setting up Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae52e9c-8ea7-4356-a7c3-9c2e0e2a55d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# Define the expected structure of the response\n",
    "class ParsedSentence(BaseModel):\n",
    "    subject: str\n",
    "    verb: str\n",
    "    obj: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c57a1171-2c16-40be-bf7a-1fc3497c7081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the request to extract parts of a simple sentence\n",
    "response = client.chat.completions.parse(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Extract the grammatical components from the sentence.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"The cat chased the mouse.\"},\n",
    "    ],\n",
    "    response_format=ParsedSentence, # This response_format parameter is the key to StructuredOut\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ac3a6f1-c942-4f0f-8dab-df70a2a01a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedChatCompletionMessage[ParsedSentence](content='{\"subject\": \"The cat\", \"verb\": \"chased\", \"obj\": \"the mouse\"}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=ParsedSentence(subject='The cat', verb='chased', obj='the mouse'), reasoning=None)\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db289817-67f9-4f67-97c8-b912745274eb",
   "metadata": {},
   "source": [
    "ðŸ”” Question: How can we extract our parsed message from this `ParsedChatCompletionMessage` Object? What fields can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4709e5ec-a6c6-4b5e-b403-c4fa9d944318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject='The cat' verb='chased' obj='the mouse'\n",
      "Subject: The cat\n",
      "Verb: chased\n",
      "Obj: the mouse\n"
     ]
    }
   ],
   "source": [
    "# To extract our Structured Response\n",
    "print(response.choices[0].message.parsed)\n",
    "\n",
    "print(\"Subject:\", response.choices[0].message.parsed.subject)\n",
    "print(\"Verb:\", response.choices[0].message.parsed.verb)\n",
    "print(\"Obj:\", response.choices[0].message.parsed.obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bb5b6-bc63-48ec-b121-f9229a27909e",
   "metadata": {},
   "source": [
    "### ðŸ¥Š [Final Challenge]: Putting it all togther - Classification using Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0994690-439e-4944-92c8-80932657181d",
   "metadata": {},
   "source": [
    "The goal of this final challenge is to combine everything you've learned to build a reliable, end-to-end workflow for structured data extraction. You will take a new narrative from an essential worker and use a Pydantic model to extract key themes in a validated, structured format.\n",
    "\n",
    "Your Goal:\n",
    "Using the DeepSeek API, your task is to create a Python script that takes the provided new_narrative as input and produces the expected_output by:\n",
    "1. **Defining a Pydantic Model**: Create a BaseModel that accurately represents the structure of the expected_output.\n",
    "2. **Building the Prompt**: Construct a messages list that includes the system prompt, a few-shot example, and the final user message containing the new_narrative.\n",
    "3. **Making the API Call**: Use the client.chat.completions.create method to call the DeepSeek model.\n",
    "4. **Validating the Response**: Use your Pydantic model to validate and parse the raw JSON string returned by the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64874045-2985-43a5-b006-9892ddd996dc",
   "metadata": {},
   "source": [
    "#### The Input\n",
    "\n",
    "This is the narrative you will be using as input for the LLM.\n",
    "\n",
    "```python\n",
    "new_narrative = \"\"\"\n",
    "In the quiet of the night, I'd mop floors at the hospital, the only sound the soft swish of the bucket. Patients came and went, doctors hurried past. Sometimes, they'd look right through me. But I'd always tell myself: someone has to keep this place clean for the healers to do their healing. That thought got me through the loneliest shifts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa77d20e-f953-4e1b-854b-1f883188e7cc",
   "metadata": {},
   "source": [
    "#### The Expected Output\n",
    "Your script should produce a Pydantic object that, when printed, looks like this. This is your target.\n",
    "\n",
    "```python\n",
    "ThematicAnalysis(emotion=['loneliness', 'dedication'], material_conditions=['hospital cleaning'], solidarity='present', theme='invisibility of labor and pride')```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b62d05-d02b-4554-94d9-d8a1e53803dc",
   "metadata": {},
   "source": [
    "Hint: You will need to define the ThematicAnalysis Pydantic class to have fields for emotion, material_conditions, solidarity, and theme, just like the previous examples. Be sure to use the correct data types and a Literal type for the solidarity field. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d4b1c5-46d6-49f3-89d1-f6704a80f4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParsedChatCompletion[ThematicAnalysis](id='gen-1755899251-sAqab8yxdqoknw0JL0dx', choices=[ParsedChoice[ThematicAnalysis](finish_reason='stop', index=0, logprobs=None, message=ParsedChatCompletionMessage[ThematicAnalysis](content='{\\n  \"emotion\": [\\n    \"Loneliness\",\\n    \"Resilience\"\\n  ],\\n  \"material_conditions\": [\\n    \"Hospital environment\",\\n    \"Night shift work\"\\n  ],\\n  \"solidarity\":  false,\\n  \"theme\": \"Invisible labor\"\\n}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, parsed=ThematicAnalysis(emotion=['Loneliness', 'Resilience'], material_conditions=['Hospital environment', 'Night shift work'], solidarity=False, theme='Invisible labor'), reasoning=None), native_finish_reason='stop')], created=1755899252, model='deepseek/deepseek-chat-v3-0324:free', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=67, prompt_tokens=101, total_tokens=168, completion_tokens_details=None, prompt_tokens_details=None), provider='Chutes')\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "# (Assuming client is already initialized)\n",
    "# Intialize Client\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\", \n",
    "  api_key=API_KEY,\n",
    ")\n",
    "\n",
    "# The new narrative to analyze\n",
    "new_narrative = \"\"\"\n",
    "In the quiet of the night, I'd mop floors at the hospital, the only sound the soft swish of the bucket. Patients came and went, doctors hurried past. Sometimes, they'd look right through me. But I'd always tell myself: someone has to keep this place clean for the healers to do their healing. That thought got me through the loneliest shifts.\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Define the Pydantic class here to match the desired output structure.\n",
    "# Hint: Your class should have fields for 'emotion', 'material_conditions', 'solidarity', and 'theme'.\n",
    "#       Remember to use the correct data types!\n",
    "#\n",
    "#       You may need to look up how to allow list datatypes in Pydantic. \n",
    "class ThematicAnalysis(BaseModel):\n",
    "    emotion: List[str]\n",
    "    material_conditions: List[str]\n",
    "    solidarity: bool\n",
    "    theme: str\n",
    "    \n",
    "\n",
    "# Step 2: Build the few-shot prompt.\n",
    "# Hint: The messages list needs a system prompt, a user/assistant example pair,\n",
    "#       and the final user message with the new narrative.\n",
    "#\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert qualitative researcher. Analyze the following narrative and extract key themes.\"},\n",
    "    {\"role\": \"user\", \"content\": new_narrative}\n",
    "]\n",
    "\n",
    "\n",
    "# Step 3: Make the API call to the DeepSeek model using `.parse`.\n",
    "# Hint: The `.parse` method handles the validation and returns a Pydantic object directly.\n",
    "#\n",
    "parsed_analysis = client.chat.completions.parse(\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    messages=messages,\n",
    "    response_format=ThematicAnalysis\n",
    ")\n",
    "\n",
    "\n",
    "# # The `parsed_analysis` variable now holds a validated Pydantic object!\n",
    "print(parsed_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "144ca32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion=['Loneliness', 'Resilience'] material_conditions=['Hospital environment', 'Night shift work'] solidarity=False theme='Invisible labor'\n"
     ]
    }
   ],
   "source": [
    "print(parsed_analysis.choices[0].message.parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ae4a3-693e-43f2-ad28-09201f8a427d",
   "metadata": {},
   "source": [
    "## Conclusion: What We've Learned\n",
    "\n",
    "In this workshop, you've moved from the conceptual understanding of LLM APIs to hands-on, programmatic control. You now have the foundational knowledge to build powerful, automated workflows with language models.\n",
    "\n",
    "Hereâ€™s a quick summary of the key concepts youâ€™ve mastered:\n",
    "\n",
    "1.  **API Mechanics:** You understand that LLM APIs are **stateless**. To simulate memory and maintain context, you are **responsible for managing the message history** yourself by sending a full list of messages with each new request.\n",
    "2.  **The Power of Roles:** You know how to use the `system`, `user`, and `assistant` roles to give the model instructions, provide it with your prompts, and capture its responses. The `system` role is particularly powerful for setting high-level rules and persona.\n",
    "3.  **Zero-Shot vs. Few-Shot Prompting:** You've seen how **zero-shot** prompting is great for general tasks but can result in inconsistent output. In contrast, **few-shot** prompting is essential for guiding the model to produce a consistent, predictable format by providing it with a single example or a few examples.\n",
    "4.  **Structured Output:** You now have the ultimate tool for reliability: **structured output with Pydantic**. By defining a `BaseModel`, you can give the LLM a clear blueprint for its response, and the `.parse` method ensures the output is always a valid, usable Python object. This is the critical step for moving from simple chat to scalable data analysis.\n",
    "\n",
    "The specific example we worked through of thematic coding of a narrative is just one use case. The most powerful concept youâ€™ve learned today is the idea of using structured output to programmatically define how the LLM should respond. This is a foundational technique that you can apply across all social science workflows, whether you are doing **data extraction**, **summarization**, or **classification**. By providing the LLM with a schema, you gain precise control over its output, making it a reliable and powerful tool for your research."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "D_Lab-M2S9YoIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
